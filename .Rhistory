View(occ_allspDF)
a <- occ_allspDF %>% filter(is.na(reportedDate)) %>% select(decimalLatitude, decimalLongitude)
View(a)
load("registros/primates_190922.RData")
load("registros/primates_190922.RData")
load("registros/primates_190922.RData")
a <- occ_allspDF %>% filter(is.na(reportedDate)) %>% select(decimalLatitude, decimalLongitude)
View(occ_allspDF_clean)
library(openxlsx)
a <- read.xlsx("registros/AM_primates_19092022_mongo.xlsx") %>% filter(is.na(reportedDate)) %>%
select(decimalLatitude, decimalLongitude)
library(dplyr)
a <- read.xlsx("registros/AM_primates_19092022_mongo.xlsx") %>% filter(is.na(reportedDate)) %>%
select(decimalLatitude, decimalLongitude)
a <- read.xlsx("registros/AM_primates_19092022_mongo.xlsx") %>%
select(decimalLatitude, decimalLongitude)
a <- read.xlsx("registros/AM_primates_19092022_mongo.xlsx") %>%
select(decimalLatitude, decimalLongitude)
load("registros/primates_190922.RData")
View(occ_allspDF_clean)
a <- occ_allspDF_clean %>% mutate(as.numeric(decimalLatitude), as.numeric(decimalLongitude))
View(a)
do_geographic_tag <- function(data_base, col_sp,  col_lon, col_lat, gazzeters = F, outliers = F,
test_gazz = c("capitals", "centroids", "equal", "gbif", "institutions",
"seas", "gbif", "zeros"),
test_outliers = c("dist", "iqr", "mad"),
outliers_details = list("tdi" = c(300,400, "variog"), "mtpl_iqr" = c(1.5, 3, 5),
"mtpl_mad" = c(1.5, 3, 5)),
thinning_res = 0.0833, mergeto_db = F, rast_DEM ="envars/wc21elev_s.tif"){
if(!require(CoordinateCleaner)) install.packages("CoordinateCleaner")
vect <- c(col_sp, col_lon, col_lat)
data_base <- data_base[, ..vect]
if(gazzeters == T){
# cada test de tipo gazzeter elegido, establecido por el vector test_gazzs, se desarrolla con la
# funciÃ³n clean_coordinates() del paquete CoordianteCleaner
gazz_results <- CoordinateCleaner::clean_coordinates(
x = data_base, lon = col_lon, lat = col_lat, species = col_sp, tests = test_gazz,
capitals_rad = 10000, centroids_rad = 1000, centroids_detail = "both", inst_rad = 100,
range_rad = 1000, country_refcol = "iso_a3", value = "spatialvalid", verbose = FALSE,
report = FALSE
)
# generar como output unicamente las columnas de los test y eliminar el summary
gazz_results <- gazz_results[, (ncol(gazz_results)-length(test_gazz)):(ncol(gazz_results)-1)]
gazz_results <- ((gazz_results)*1) |> as.data.table()
}
if(outliers == T){
outl_list <- list()
for(i in 1:length(test_outliers)){
test_i <- test_outliers[i]
# seleccionar de la lista outliers_details cada uno de los parametros que necesita cada test
if(test_i == "dist"){
tdi = outliers_details[["tdi"]]
method_i <- "distance"
}else if(test_i == "iqr"){
mltpl = outliers_details[["mtpl_iqr"]]
method_i <- "quantile"
}else if(test_i == "mad"){
mltpl = outliers_details[["mtpl_mad"]]
method_i <- "mad"
}
if(test_i == "iqr"){
outl_mltpl <- list()
for(a in 1:length(mltpl)){
outl_a <- cc_outl(
x = data_base, lon = col_lon, lat = col_lat, species = col_sp, method = method_i,
tdi = tdi, mltpl = mltpl[a], value = "flagged", sampling_thresh = 0, min_occs = 7, thinning = T,
thinning_res = thinning_res, verbose = F) |> as.data.table()
outl_mltpl[[a]] <- outl_a
}
outl_mltpl <- do_call(cbind, outl_mltpl)
colnames(outl_mltpl) <- paste0("_", mltpl)
outl_list[["iqr"]] <- outl_mltpl
}
if(test_i == "mad"){
outl_mltpl <- list()
for(a in 1:length(mltpl)){
outl_a <- cc_outl(
x = data_base, lon = col_lon, lat = col_lat, species = col_sp, method = method_i,
tdi = tdi, mltpl = mltpl[a], value = "flagged", sampling_thresh = 0, min_occs = 7, thinning = T,
thinning_res = thinning_res, verbose = F) |> as.data.table()
outl_mltpl[[a]] <- outl_a
}
outl_mltpl <- do_call(cbind, outl_mltpl)
colnames(outl_mltpl) <- paste0("_", mltpl)
outl_list[["mad"]] <- outl_mltpl
}
if(test_i == "dist"){
index_num <- grepl("(\\d+)", x = tdi)
if(sum(index_num) != 0){
num_tdi <- tdi[index_num] |> as.numeric()
outl_tdi <- list()
for(a in 1:length(num_tdi)){
outl_a <- cc_outl(
x = data_base, lon = col_lon, lat = col_lat, species = col_sp, method = method_i,
tdi = num_tdi[a], mltpl = mltpl, value = "flagged", sampling_thresh = 0, min_occs = 7, thinning = T,
thinning_res = thinning_res, verbose = F) |> as.data.table()
outl_tdi[[a]] <- outl_a
}
outl_tdi <- do_call(cbind, outl_tdi)
colnames(outl_tdi) <- paste0("_", num_tdi, "_km")
outl_list[["tdi"]] <- outl_tdi
}
if("variog" %in% tdi){
if(!require(automap)) install.packages("automap")
if(!require(sp)) install.packages("sp")
r <- rast_DEM %>% rast()
tmp <- data_base
tmp$r_DEM <- extract(r, as.data.frame(data_base)[,c(col_lon, col_lat)])[,2]
tmp <- na.omit(tmp)
coordinates(tmp) <-  ~ decimalLongitude + decimalLatitude
emp_Var <- autofitVariogram(formula = r_DEM ~ 1, input_data =  tmp)
distx <- emp_Var$var_model[2,"range"]*111
outl_variog <- cc_outl(
x = data_base, lon = col_lon, lat = col_lat, species = col_sp, method = method_i,
tdi = distx, mltpl = mltpl, value = "flagged", sampling_thresh = 0, min_occs = 7, thinning = T,
thinning_res = thinning_res, verbose = F) |> as.data.table()
colnames(outl_variog) <- paste0("_", round(distx,0), "_km")
outl_list[["variog"]] <- outl_variog
}
}
}
outliers_results <- do_call(cbind, outl_list)
colnames(outliers_results) <- paste0("geo.", colnames(outliers_results))
outliers_results <- ((outliers_results)*1) |> as.data.table()
}
# compilar resultados segun la categoria de test desarollado
if(exists("gazz_results") & !exists("outliers_results")){
results <- gazz_results
}else if(!exists("gazz_results") & exists("outliers_results")){
results <- outliers_results
}else if(exists("gazz_results") & exists("outliers_results")){
results <- cbind(gazz_results, outliers_results)
}
return(results)
}
# B.2 etiquetado ambiental
do_environmental_tag <- function(
env = envars, data_base, col_lon, col_lat, univar = F, multivar = F,
test_univar = c("zscore", "std", "iqr", "rjack", "mad" ), test_multivar = c("pca_error", "maha"),
univar_details = list("mtpl_std" = 3, "mtpl_iqr" = c(1.5, 3, 5), "mtpl_mad" = c(1.5, 3, 5)),
multivar_details = c("pval" = 0.95), min_occs = 7
){
env_space <- gen_env_space(env. = env, data.base = data_base, col.lon = col_lon, col.lat = col_lat)
if(univar == T){
# inicializar output
outl_list <- list()
if(nrow(data_base) <=  min_occs){
return(out_univar)
}else{
for(i in 1:ncol(env_space)){
x <-  env_space[, ..i] |> as.matrix() |> as.vector()
xi <- na.omit(x)
xNA <- which(is.na(x) == T)
out_ <- list()
for(a in 1:length(test_univar)){
test_a <- test_univar[a]
if (test_a == "zscore"){
z <- calc_zscore(x = xi )
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
z <- append(x = z, values = NA, after = xNA[f]-1 )
}
}
out_[["zscore"]] <- z
}
if (test_a == "std"){
mltpl <- univar_details[["mtpl_std"]]
std_v <- ((!calc_std(x = xi , threshold = mltpl))*1)
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
std_v <- append(x = std_v, values = NA, after = xNA[f]-1 )
}
}
out_[["std"]] <- std_v
}
if (test_a == "rjack"){
rjackv <- (!calc_rjack(x = xi ))*1
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
rjackv <- append(x = rjackv, values = NA, after = xNA[f]-1 )
}
}
out_[["rjack"]] <- rjackv
}
if(test_a == "iqr"){
mltpl <- univar_details[["mtpl_iqr"]]
out_a <- list()
for(c in 1:length(mltpl)){
out_c <- (!iqr(x = xi, mtp = mltpl[c]))*1
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
out_c <- append(x = out_c, values = NA, after = xNA[f]-1 )
}
}
out_a[[c]] <- out_c
}
out_a <- do_call(cbind, out_a) |> as.data.table()
colnames(out_a) <- paste0("_", mltpl)
out_[["iqr"]] <- out_a
}
if(test_a == "mad"){
mltpl <- univar_details[["mtpl_mad"]]
out_a <- list()
for(c in 1:length(mltpl)){
out_c <- (!calc_mad(x = xi, threshold = mltpl[c]))*1
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
out_c <- append(x = out_c, values = NA, after = xNA[f]-1 )
}
}
out_a[[c]] <- out_c
}
out_a <- do_call(cbind, out_a) |> as.data.table()
colnames(out_a) <- paste0("_", mltpl)
out_[["mad"]] <- out_a
}
}
out_ <- do_call(cbind, out_)
var <- colnames(env_space)[i]
outl_list[[var]] <- out_
}
}
univar_results <- do_call(cbind, outl_list)
}
if(multivar == T){
out_multivar <- list()
# hallar los datos perdidos, no pueden ser trabajados en los test multivariados
xNA <- apply(X = env_space, 2, FUN = function(X){which(is.na(X))}) |> unlist() |> unique()
if(is.matrix(xNA)){
xNA <- xNA %>% as.vector() %>% unique()
}
# media y escalar las variables
if(length(xNA)!= 0){
mu <-  colMeans(env_space[-xNA, ])
env_space_scale <-  scale(env_space[-xNA, ], center = mu, scale = T)
}else{
mu <-  colMeans(env_space)
env_space_scale <-  scale(env_space, center = mu, scale = T)
}
if("pca_error" %in% test_multivar){
#calcular PCA
Xpca <- prcomp(x = env_space_scale)
#establecer la varianza compuesta de los componentes
summary_pca <- summary(Xpca)
prop <- (summary_pca$sdev^2 / sum(summary_pca$sdev^2)) |> cumsum()
#elegir aquellos en donde se complete el x porcentaje de varianza a trabajar
nComp <- which(prop >= multivar_details["pval"])[1]
# recrear el dataset escalado y establecer la diferencia entre el original y el predicho
Xhat <-  Xpca$x[,1:nComp] %*% t(Xpca$rotation[,1:nComp])
errorq_pca <- (env_space_scale - Xhat)^2
# el resto de errores por cada variable estan correlacionados al 100% por lo que el
# error de pca en una variable predicha nos habla de todas las otras
errorq_pca <- errorq_pca[,1] |> round(5)
# agregar aquellos registros con datos perdidos
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
errorq_pca <- append(x = errorq_pca, values = NA, after = xNA[f]-1 )
}
}
out_multivar[["pca_error"]] <- errorq_pca
}
if("maha" %in% test_multivar){
if(!require(ClassDiscovery)) install.packages("ClassDiscovery")
# establecer la distancia de mahalanobis y hallar valores de probabilidad
dist.maha <- mahalanobis(env_space_scale, colMeans(env_space_scale), cov(env_space_scale)) %>% round(2)
pvalue <- pchisq(dist.maha, df=ncol(env_space_scale)-1, lower.tail=FALSE)
# binarizar los valores de probabilidad, marcando los que esten por debajo
# de significatividad estadistica deseada 1 - pvalor
pvalue <- !(pvalue <= (1- multivar_details["pval"]))
pvalue <- pvalue*1
# agregar valores NA
if(length(xNA)!= 0){
for(f in 1:length(xNA)){
dist.maha <- append(x = dist.maha, values = NA, after = xNA[f]-1 )
pvalue <- append(x = pvalue, values = NA, after = xNA[f]-1 )
}
}
maha <- cbind(dist.maha, pvalue) |> as.data.frame()
# adjuntar a la data.frame de salida
out_multivar[["maha"]] <- maha$dist.maha
out_multivar[["pvalue"]] <- maha$pvalue
}
multivar_results <- do_call(cbind, out_multivar)
}
# compilar resultados segun la categoria de test desarollado
if(exists("univar_results") & !exists("multivar_results")){
results <- univar_results
}else if(!exists("univar_results") & exists("multivar_results")){
results <- multivar_results
}else if(exists("univar_results") & exists("multivar_results")){
results <- cbind(univar_results, multivar_results)
}
return(results)
}
#-------------------------------------------------------------------------------
# C.1 Modulo biogeografico
do_biogeographic_tag <- function(
data_base, col_sp, col_lon, col_lat, col_dup, shapeLayers = NULL, polynames,
test_biog = c("bracatus", "speciesGeo", "IaVH"), biog_details = c("pval" = 0.95),
min_occs = 7
){
out_biogeo <- list()
sf::sf_use_s2(FALSE)
data_base <- as.data.frame(data_base)
#Extraer columnas de especie y coordenadas de la base de datos de registros de presencia
pts <- data_base[, c(col_sp, col_lon, col_lat)]
rm(data_base);gc()
# Loop que clasifica cada capa shape que fue cargado
for(i in 1:length(shapeLayers)){
print(paste0("shapelayer = ", i))
if("speciesGeo" %in% test_biog){
shp_nm <- abbreviate(names(shapeLayers)[i])
nm <- paste0("SpGeo", ".", shp_nm)
#extraer de la lista de shapefiles el indice i
shapeLayers_i <- shapeLayers[[i]]
polynames_i <- polynames[i]
# darle nombres al data frame de la base de datos aceptados por species geocoder
colnames(pts) <- c("species", "decimalLongitude", "decimalLatitude")
# extraer poligonos en donde caen los registros de presencia
shp_ref <- shapeLayers_i[gen.st.points(pts, collon = "decimalLongitude",
collat = "decimalLatitude"), ]
# clasificar los puntos en los poligonos del shapefile de referencia usando una frecuencia de
# 1-pval en terminos de porcentaje
sp.class <- SpGeoCod(x = pts, y = as_Spatial(shp_ref), areanames = polynames_i,
occ.thresh =  (1-biog_details["pval"])*100)
# extraer aquellos poligonos en donde quedaron clasificados los registros
geocode <- sp.class$spec_table
geocode <- colnames(geocode)[which(geocode[1, ] != 0)]
# Extraer la clasificaciÃ³n de cada registro en el poligono
samples <- sp.class$samples[, "homepolygon"]
# Transformar la clasificaciÃ³n: aquellos registros clasificados darle valor de 0,
# aquellos que no fueron clasificados dado que estan dentro del margen de error
# darle valor 1
geocode_samples <- rep(NA, length(samples))
for(x in 1:length(geocode)){
geocode_x <- which(samples == geocode[x])
geocode_samples[geocode_x] <- 1
}
geocode_samples[is.na(geocode_samples)] <- 0
# Crear tabla de resultados de speciesGeocodeR
results_SpeGeo <- data.frame(geocode_samples)
colnames(results_SpeGeo) <- nm
# agregar al shapefile una columna que identifique cada poligono como anomalo o no
shp_polyname_vect <- st_drop_geometry(shp_ref) %>% dplyr::pull(polynames_i)
shp_ref[, nm] <- shp_polyname_vect %in% geocode
}
if("bracatus" %in% test_biog){
if(!("speciesGeo" %in% test_biog) & !("IaVH" %in% test_biog)){
stop("Si desea correr bracatus es necesario que esten activos alguno de los dos metodos de
clasificaciÃ³n de puntos inicial: 'speciesGeo' o 'IaVH'")
}
if(!require(raster)) install.packages("raster")
shp_ref_sp <- shp_ref %>% as_Spatial()
logic_ref <- shp_ref_sp@data[ , nm] %>% unique()
if(length(logic_ref) >= 2){
range_map <- range_maps(range = shp_ref_sp, biogeo = nm, native = T, alien = F)
signals <- signalCalculation (ref_reg = range_map, pts = pts, biogeo = F) #time consuming
acc <- accuracy (signals) %>% dplyr::select(accuracy)
}else{
acc <- data.frame(rep(1, nrow(pts)))
}
results_bracatus <- acc
colnames(results_bracatus) <- paste0("bRa", ".", shp_nm)
}
# compilar resultados segun la categoria de test desarollado
if(exists("results_SpeGeo") & !exists("results_bracatus")){
results_i <- results_SpeGeo
}else if(exists("results_SpeGeo") & exists("results_bracatus")){
results_i <- cbind(results_SpeGeo, results_bracatus)
}
out_biogeo[[i]] <- results_i
}
return(dplyr::bind_cols(out_biogeo))
}
#-------------------------------------------------------------------------------
# Funciones individuales
#-------------------------------------------------------------------------------
# Correlaciones ambientales
do_corr_envars <- function(envars = envars, sample_size = 10000){
if(!require(terra)) install.packages("terra")
sample_envars <- terra::spatSample(envars, size = 10000, method = "random", replace = F, na.rm = T,
as.df= T)
correlacion <- sample_envars |> cor()
return(correlacion)
}
#-------------------------------------------------------------------------------
# Extraer espacio ambiental
gen_env_space <- function(env. = env, data.base = data_base, col.lon = col_lon, col.lat = col_lat){
vect <- c(col.lon, col.lat)
geodata <- data.base[, ..vect] |> data.frame()
env.space <- terra::extract(env., geodata)[, -1] |> data.table()
return(env.space)
}
#-------------------------------------------------------------------------------
# generar capa espacial de puntos
gen_sf_points <- function(dat, collon = col.lon, collat = col.lat) {
st.points <- dat |>
dplyr::select(collon, collat) |>
st_as_sf(coords = c(collon, collat), crs = st_crs("EPSG:4326")) |>
st_transform(st_crs("EPSG:4326"))
}
calc_zscore <- function(x){
values <- (x - mean(x, na.rm = T)) / sd(x, na.rm = T)
return( values )
}
calc_std <- function(x, threshold){
std <- sd(x, na.rm = T)
mean <- mean(x, na.rm = T)
return ( (x < mean - (threshold * std)) | (x > mean + (threshold * std)) )
}
calc_mad <- function(x, threshold){
madx <- stats::mad(x, na.rm = T)
medianx <- median(x, na.rm = T)
return ( (x < medianx - (threshold * madx)) | (x > medianx + (threshold * madx)) )
}
calc_iqr <- function(x, mtp){
rangeIQR <- IQR(x, na.rm = T)
quants <- quantile(x, na.rm = T)
q1 <- quants[2]
q3 <- quants[4]
return ( (x < q1 - (mtp * rangeIQR)) | (x > q3 + (mtp * rangeIQR)) )
}
calc_rjack <- function (x)
{
xout <- x
xx <- x
x <- unique(x)
rng <- diff(range(x, na.rm = T))
mx <- mean(x, na.rm = T)
n <- as.numeric(length(x))
n1 <- abs(n - 1)
t1 <- (0.95 * sqrt(n)) + 0.2
x <- sort(x)
y <- rep(0, n1)
for (i in 1:n1) {
x1 <- x[i + 1]
if (x[i] < mx) {
y[i] <- (x1 - x[i]) * (mx - x[i])
}else {
y[i] <- (x1 - x[i]) * (x1 - mx)
}
}
my <- mean(y, na.rm = T)
z <- y/(sqrt(sum((y - my)^2)/n1))
out <- rep(0, length(xx))
if (any(z > t1)) {
f <- which(z > t1)
v <- x[f]
if (v < median(x)) {
xa <- (xx <= v) * 1
out <- out + xa
}
if (v > median(x)) {
xb <- (xx >= v) * 1
out <- out + xb
}
}else{
out <- out
}
return(out)
}
insert_row <- function(existingDF, newrow, r) {
existingDF[seq(r+1,nrow(existingDF)+1),] <- existingDF[seq(r,nrow(existingDF)),]
existingDF[r,] <- newrow
existingDF
}
#-------------------------------------------------------------------------------
range_maps <- function (range, biogeo = "legend", native = "Extant (resident)",
alien = "Introduced")
{
range_native <- range[which(range@data[, biogeo] %in% native),
]
range_alien <- range[which(range@data[, biogeo] %in% alien),
]
raster_2degrees <- raster::raster(vals = NA, res = 2)
raster_cut <- raster::crop(raster_2degrees, raster::extent(range) + c(-2, 2, -2, 2))
range2 <- rasterize(range, raster_cut, getCover = TRUE)
range3 <- raster::rasterToPolygons(range2)
range4 <- range3[which(range3$layer != 0), ]
range4$data <- 1
range4 <- range4[which(range4$layer >= 0.05), ]
range4$area <- raster::area(range4)/1e+06
range_native2 <- rasterize(range_native, raster_cut, getCover = TRUE)
range_native3 <- raster::rasterToPolygons(range_native2)
range_native4 <- range_native3[which(range_native3$layer !=
0), ]
range_native4$data <- 1
range_native4 <- range_native4[which(range_native4$layer >=
0.05), ]
range_native4@data
range_native4$area <- raster::area(range_native4)/1e+06
range_alien2 <- rasterize(range_alien, raster_cut, getCover = TRUE)
range_alien3 <- raster::rasterToPolygons(range_alien2)
range_alien4 <- range_alien3[which(range_alien3$layer !=
0), ]
range_alien4$data <- 1
range_alien4 <- range_alien4[which(range_alien4$layer >= 0.01), ]
range_alien4$area <- raster::area(range_alien4)/1e+06
range_list <- list(range4, range_native4, range_alien4)
names(range_list) <- c("Presence", "Native",
"Alien")
return(range_list)
}
#--------------------
give_msg_time <- function(time.1) {
time.2 <- Sys.time()
# Time spent
alltime <- round(as.numeric(difftime(time.2, time.1, units = "mins")), 2)
t.sec <- round((alltime - trunc(alltime)) * 60)
msg <- paste("Completed in ", trunc(alltime), "min", t.sec, "sec\n")
return(msg)
}
